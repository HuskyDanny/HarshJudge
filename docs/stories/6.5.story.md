# Story 6.5: Step-Based Agent Execution

## Status

Done

## Story

**As a** HarshJudge user,
**I want** each step to execute in its own spawned agent,
**so that** token context is naturally isolated and managed.

## Acceptance Criteria

1. `run.md` workflow spawns a new Task agent for each step
2. Each agent receives only:
   - The step's `.md` file content
   - Project `prd.md` context (summarized)
   - Previous step result (pass/fail, not full evidence)
3. Agent returns concise result:
   - Status (pass/fail)
   - Evidence file paths (not content)
   - Error message (if failed)
4. Main agent tracks progress via `result.json`:
   - Reads `meta.yaml` for step order
   - Updates `result.json` after each step
   - Determines next step or stops on failure
5. Token optimization is automatic — no manual management needed
6. (Absorbs Story 5.1 token optimization goals)

## Tasks / Subtasks

- [x] Task 1: Update SKILL.md with step-based agent pattern (AC: 1, 5)
  - [x] Open `skills/harshjudge/SKILL.md`
  - [x] Add "Step-Based Execution" section explaining agent spawning
  - [x] Document per-step agent isolation pattern
  - [x] Include agent prompt template for step execution
  - [x] Remove reference to deprecated `iterations.md`

- [x] Task 2: Rewrite run.md for step-based workflow (AC: 1, 2, 3, 4)
  - [x] Open `skills/harshjudge/references/run.md`
  - [x] Update workflow to: read meta.yaml → loop through steps → spawn agent per step
  - [x] Define step agent prompt template with: step content, PRD summary, previous result
  - [x] Define step agent return format: status, evidencePaths, error
  - [x] Include progress tracking with result.json updates
  - [x] Embed Playwright tools reference (from Story 6.6)

- [x] Task 3: Create step execution agent prompt template (AC: 2, 3)
  - [x] Design prompt template with clear boundaries:
    ```
    Execute step {stepId} of scenario {scenarioSlug}:

    ## Step Content
    {stepContent}

    ## Project Context (from prd.md)
    {prdSummary}

    ## Previous Step Result
    {previousStepStatus}

    ## Instructions
    1. Execute the actions described in the step
    2. Capture before/after screenshots using recordEvidence
    3. Return ONLY: { status, evidencePaths, error }
    ```
  - [x] Include Playwright tool usage guidance
  - [x] Include evidence naming conventions

- [x] Task 4: Update startRun to return step list (AC: 4)
  - [x] Verify `startRun` returns `steps` array (from meta.yaml)
  - [x] Ensure step list includes id, title, file for each step
  - [x] Main agent uses this list to orchestrate execution

- [x] Task 5: Define main agent orchestration flow (AC: 4)
  - [x] Document the orchestration loop in run.md:
    ```
    1. Call startRun → get runId, steps[]
    2. For each step in steps:
       a. Read step file content
       b. Spawn step agent with prompt
       c. Agent returns { status, evidencePaths, error }
       d. Call completeStep with result
       e. If fail, stop loop
    3. Call completeRun with final status
    ```
  - [x] Include error handling for agent failures

- [x] Task 6: Update iterate.md for step-based scenarios (AC: 1)
  - [x] Open `skills/harshjudge/references/iterate.md`
  - [x] Update to reference individual step files
  - [x] Update to use per-step evidence directories
  - [x] Remove references to monolithic scenario.md

- [x] Task 7: Write integration test scenario (AC: 1-5)
  - [x] Create test scenario in `examples/` or document manual test
  - [x] Verify token isolation works (agent context is isolated)
  - [x] Verify progress tracking in result.json
  - [x] Verify step failure stops execution

## Dev Notes

### Architecture References

**Step-Based Agent Pattern** [Source: architecture/appendix-b-sample-scenario-template.md]
Each step executes in isolation:
1. Main agent reads scenario meta.yaml
2. Main agent spawns Task agent for step 01
3. Step agent executes, records evidence, returns summary
4. Main agent calls completeStep, checks nextStepId
5. Repeat for each step until done or failure

**Agent Spawning Pattern** [Source: skills/harshjudge/references/agent-pattern.md]
```
Task tool with subagent_type: "general-purpose"

Prompt template:
"Execute step {stepId} of scenario {scenarioSlug}:

## Step Content
{read from steps/{stepId}-{slug}.md}

## Project Context
{summarized from .harshJudge/prd.md}

## Previous Step
Status: {pass|fail|first step}

## Your Task
1. Execute the actions using Playwright MCP tools
2. Capture before/after screenshots
3. Record evidence using recordEvidence tool with stepId: "{stepId}"
4. Return ONLY a JSON object:
{
  "status": "pass" | "fail",
  "evidencePaths": ["path1", "path2"],
  "error": null | "error message"
}

DO NOT return full evidence content. DO NOT explain your work."
```

**StartRunResult with Steps** [Source: architecture/5-api-specification-mcp-tools.md#5.1]
```typescript
export interface StartRunResult {
  success: boolean;
  runId: string;
  runNumber: number;
  runPath: string;
  steps: Array<{
    id: string;
    title: string;
    file: string;
  }>;
  startedAt: string;
}
```

**Orchestration Flow in run.md**:
```
1. Call startRun(scenarioSlug)
   → Returns: runId, steps[]

2. Read .harshJudge/prd.md for project context (summarize)

3. For each step in steps:
   a. Read step file: .harshJudge/scenarios/{slug}/steps/{step.file}

   b. Spawn Task agent:
      - subagent_type: "general-purpose"
      - prompt: step execution template (see above)

   c. Agent returns: { status, evidencePaths, error }

   d. Call completeStep(runId, stepId, status, duration, error)
      → Returns: nextStepId or null

   e. If status === 'fail' or nextStepId === null:
      - Break loop
      - Call completeRun with fail status

4. If all steps passed:
   - Call completeRun with pass status

5. Report final results to user
```

### File Locations

| Purpose | Path |
|---------|------|
| Main skill file | `skills/harshjudge/SKILL.md` |
| Run workflow | `skills/harshjudge/references/run.md` |
| Iterate workflow | `skills/harshjudge/references/iterate.md` |
| Agent pattern (to embed) | `skills/harshjudge/references/agent-pattern.md` |
| Playwright tools (to embed) | `skills/harshjudge/references/playwright-tools.md` |

### Key Implementation Notes

1. **Token Isolation**: Each step agent has its own context. Main agent only receives summary results. Large outputs (screenshots, logs) are saved to files, not returned in agent response.

2. **PRD Summary**: Don't pass full prd.md to step agent. Extract relevant sections:
   - App type and base URL
   - Auth credentials if step involves login
   - Relevant tech stack info

3. **Previous Step Context**: Only pass status (pass/fail) and step ID. Don't pass error details or evidence from previous steps unless debugging.

4. **Agent Timeout**: Consider adding guidance on timeout handling. If agent takes too long, main agent should handle gracefully.

5. **Error Recovery**: Step agent failure should be caught by main agent. Result in completeStep call with fail status. Main agent decides whether to continue or stop.

6. **Evidence Paths**: Step agent returns paths like `.harshJudge/scenarios/{slug}/runs/{runId}/step-{id}/evidence/before.png`. Main agent doesn't need to read file content.

### Skill File Changes Summary

**SKILL.md Updates**:
- Add step-based execution overview
- Update project structure to show steps/ directory
- Update MCP tools quick reference (add completeStep, createScenario)
- Remove `iterations.md` reference

**run.md Rewrite**:
- Replace monolithic execution with step-loop pattern
- Add agent prompt template section
- Include Playwright tools inline (from playwright-tools.md)
- Update evidence paths for per-step structure

**iterate.md Updates**:
- Reference individual step files for editing
- Update evidence paths to step-XX directories
- Update example commands for new structure

### Testing

This story primarily involves skill file documentation updates. Testing is manual:

1. **Manual Test**: Run a multi-step scenario and verify:
   - Each step spawns separate agent
   - result.json shows per-step results
   - Evidence is in step-XX directories
   - Failure stops execution

2. **Token Verification**: Compare token usage between old (monolithic) and new (step-based) approaches on a 5+ step scenario.

## Change Log

| Date | Version | Description | Author |
|------|---------|-------------|--------|
| 2025-12-18 | 1.0 | Initial story draft | SM Agent (Bob) |
